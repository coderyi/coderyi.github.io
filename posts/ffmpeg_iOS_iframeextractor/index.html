<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>ffmpeg在iOS的使用-iFrameExtractor源码解析</title>

    <meta name="viewport" content="width=device-width">
    <meta name="description" content="">

    
    

    <link rel="canonical" href="http://localhost:4000/posts/ffmpeg_iOS_iframeextractor/">
    <link rel="icon" type="image/png" href="/images/logo.png">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/monster.css">

    

</head>


    <body>
    
    <div class="wrapper">

      <header class="header">

  <div class="site-title">
    
    <h4 class="entry-title"><a href="/posts/ffmpeg_iOS_iframeextractor/">ffmpeg在iOS的使用-iFrameExtractor源码解析</a></h4>
    
  </div>

<div class="links">
    
    <a href="/" class="page-link">Blog</a>
    
    
    
    
      <a class="page-link"
        href="/about/">About</a>
    
    
    
      <a class="page-link"
        href="/categories/">Categories</a>
    
    
    
    
    
    
    
    
    
      <a class="page-link"
        href="/tags/">Tags</a>
    
    
    <a href="/feed.xml" target="_blank" class="page-link">RSS</a>
</div>
</header>

      
      <div class="navi">
    
    <a href="/" class="page-link">Blog</a>
    
    
    
    
      <a class="page-link"
        href="/about/">About</a>
    
    
    
      <a class="page-link"
        href="/categories/">Categories</a>
    
    
    
    
    
    
    
    
    
      <a class="page-link"
        href="/tags/">Tags</a>
    
    
    <a href="/feed.xml" target="_blank" class="page-link">RSS</a>
</div>


      <div class="content">
        <div class="articles">
            <div class="entry post">

	<div class="entry-content">
	  <article class="entry-body">
	  	
	  		<p>iFrameExtractor地址:<a href="https://github.com/lajos/iFrameExtractor">https://github.com/lajos/iFrameExtractor</a></p>

<h2 id="ffmpeg的简介">ffmpeg的简介</h2>

<p>FFmpeg是一套可以用来记录、转换数字音频、视频，并能将其转化为流的开源计算机程序。</p>

<p>“FFmpeg”这个单词中的”FF”指的是”Fast Forward”。</p>

<h6 id="ffmpeg支持的格式">ffmpeg支持的格式</h6>

<p>ASF</p>

<p>AVI</p>

<p>BFI</p>

<p>FLV</p>

<p>GXF, General eXchange Format, SMPTE 360M</p>

<p>IFF</p>

<p>RL2</p>

<p>ISO base media file format（包括QuickTime, 3GP和MP4）</p>

<p>Matroska（包括WebM）</p>

<p>Maxis XA</p>

<p>MPEG program stream</p>

<p>MPEG transport stream（including AVCHD）</p>

<p>MXF, Material eXchange Format, SMPTE 377M</p>

<p>MSN Webcam stream</p>

<p>Ogg</p>

<p>OMA</p>

<p>TXD</p>

<p>WTV</p>

<h6 id="ffmpeg支持的协议">ffmpeg支持的协议</h6>

<p>IETF标准：TCP, UDP, Gopher, HTTP, RTP, RTSP和SDP</p>

<p>苹果公司的相关标准：HTTP Live Streaming</p>

<p>RealMedia的相关标准：RealMedia RTSP/RDT</p>

<p>Adobe的相关标准：RTMP, RTMPT（由librtmp实现），RTMPE（由librtmp实现），RTMPTE（由librtmp）和RTMPS（由librtmp实现）</p>

<p>微软的相关标准：MMS在TCP上和MMS在HTTP上</p>

<h2 id="iframeextractor的使用">iFrameExtractor的使用</h2>

<p>初始化</p>
<pre>
self.video = [[VideoFrameExtractor alloc] initWithVideo:[Utilities bundlePath:@"sophie.mov"]];

	video.outputWidth = 426;
	video.outputHeight = 320;
</pre>

<p>播放</p>

<pre>
	[video seekTime:0.0];
	[NSTimer scheduledTimerWithTimeInterval:1.0/30
									 target:self
								   selector:@selector(displayNextFrame:)
								   userInfo:nil
									repeats:YES];
</pre>

<pre>
-(void)displayNextFrame:(NSTimer *)timer {
	if (![video stepFrame]) {

		return;
	}
	imageView.image = video.currentImage;

}
</pre>

<h2 id="videoframeextractor类解析">VideoFrameExtractor类解析</h2>

<h6 id="initwithvideonsstring-moviepath方法">initWithVideo:(NSString *)moviePath方法</h6>

<p>VideoFrameExtractor的初始化，主要是配置三个全局的结构体变量。</p>

<p>AVFormatContext类型的pFormatCtx，AVFormatContext主要存储视音频封装格式中包含的信息；AVInputFormat存储输入视音频使用的封装格式。每种视音频封装格式都对应一个AVInputFormat 结构。</p>

<p>AVCodecContext类型的pCodecCtx ，每个AVStream存储一个视频/音频流的相关数据；每个AVStream对应一个AVCodecContext，存储该视频/音频流使用解码方式的相关数据；每个AVCodecContext中对应一个AVCodec，包含该视频/音频对应的解码器。每种解码器都对应一个AVCodec结构。</p>

<p>AVFrame类型的pFrame，视频的话，每个结构一般是存一帧，音频可能有好几帧。解码前数据是AVPacket，解码后数据是AVFrame。</p>

<p>FMPEG中结构体很多。最关键的结构体他们之间的对应关系如下所示：</p>

<p><img src="http://img.blog.csdn.net/20130914204051125?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" width="440" height="179" /></p>

<p>图片来自:<a href="http://blog.csdn.net/leixiaohua1020/article/details/11693997">FFMPEG中最关键的结构体之间的关系</a></p>

<p>下面就是初始化的代码</p>
<pre>
-(id)initWithVideo:(NSString *)moviePath {
	if (!(self=[super init])) return nil;
 
    AVCodec         *pCodec;
		
    // Register all formats and codecs
    avcodec_register_all();
    av_register_all();
	
    // Open video file
    if(avformat_open_input(&amp;pFormatCtx, [moviePath cStringUsingEncoding:NSASCIIStringEncoding], NULL, NULL) != 0) {
        av_log(NULL, AV_LOG_ERROR, "Couldn't open file\n");
        goto initError;
    }
	
    // Retrieve stream information
    if(avformat_find_stream_info(pFormatCtx,NULL) &lt; 0) {
        av_log(NULL, AV_LOG_ERROR, "Couldn't find stream information\n");
        goto initError;
    }
    
    // Find the first video stream
    if ((videoStream =  av_find_best_stream(pFormatCtx, AVMEDIA_TYPE_VIDEO, -1, -1, &amp;pCodec, 0)) &lt; 0) {
        av_log(NULL, AV_LOG_ERROR, "Cannot find a video stream in the input file\n");
        goto initError;
    }
	
    // Get a pointer to the codec context for the video stream
    pCodecCtx = pFormatCtx-&gt;streams[videoStream]-&gt;codec;
    
    // Find the decoder for the video stream
    pCodec = avcodec_find_decoder(pCodecCtx-&gt;codec_id);
    if(pCodec == NULL) {
        av_log(NULL, AV_LOG_ERROR, "Unsupported codec!\n");
        goto initError;
    }
	
    // Open codec
    if(avcodec_open2(pCodecCtx, pCodec, NULL) &lt; 0) {
        av_log(NULL, AV_LOG_ERROR, "Cannot open video decoder\n");
        goto initError;
    }
	
    // Allocate video frame
    pFrame = avcodec_alloc_frame();
			
	outputWidth = pCodecCtx-&gt;width;
	self.outputHeight = pCodecCtx-&gt;height;
			
	return self;
	
initError:
	[self release];
	return nil;
}
</pre>

<h6 id="sourcewidth和sourceheight方法">sourceWidth和sourceHeight方法</h6>

<p>获取屏幕的宽和高</p>
<pre>
-(int)sourceWidth {
	return pCodecCtx-&gt;width;
}

-(int)sourceHeight {
	return pCodecCtx-&gt;height;
}

</pre>

<h6 id="setupscaler方法">setupScaler方法</h6>

<p>设置视频播放视图的尺寸</p>
<pre>
-(void)setupScaler {

	// Release old picture and scaler
	avpicture_free(&amp;picture);
	sws_freeContext(img_convert_ctx);	
	
	// Allocate RGB picture
	avpicture_alloc(&amp;picture, PIX_FMT_RGB24, outputWidth, outputHeight);
	
	// Setup scaler
	static int sws_flags =  SWS_FAST_BILINEAR;
	img_convert_ctx = sws_getContext(pCodecCtx-&gt;width, 
									 pCodecCtx-&gt;height,
									 pCodecCtx-&gt;pix_fmt,
									 outputWidth, 
									 outputHeight,
									 PIX_FMT_RGB24,
									 sws_flags, NULL, NULL, NULL);
	
}
</pre>

<h6 id="duration方法">duration方法</h6>

<p>获取音视频文件的总时间</p>
<pre>
-(double)duration {
	return (double)pFormatCtx-&gt;duration / AV_TIME_BASE;
}
</pre>

<h6 id="currenttime方法">currentTime方法</h6>

<p>显示音视频当前播放的时间</p>
<pre>
-(double)currentTime {
    AVRational timeBase = pFormatCtx-&gt;streams[videoStream]-&gt;time_base;
    return packet.pts * (double)timeBase.num / timeBase.den;
}
</pre>

<h6 id="seektimedoubleseconds方法">seekTime:(double)seconds方法</h6>

<p>直接跳到音视频的第seconds秒进行播放，默认从第0.0秒开始</p>
<pre>
-(void)seekTime:(double)seconds {
	AVRational timeBase = pFormatCtx-&gt;streams[videoStream]-&gt;time_base;
	int64_t targetFrame = (int64_t)((double)timeBase.den / timeBase.num * seconds);
	avformat_seek_file(pFormatCtx, videoStream, targetFrame, targetFrame, targetFrame, AVSEEK_FLAG_FRAME);
	avcodec_flush_buffers(pCodecCtx);
}
</pre>

<h6 id="stepframe方法">stepFrame方法</h6>

<p>解码视频得到帧</p>
<pre>
-(BOOL)stepFrame {
	// AVPacket packet;
    int frameFinished=0;

    while(!frameFinished &amp;&amp; av_read_frame(pFormatCtx, &amp;packet)&gt;=0) {
        // Is this a packet from the video stream?
        if(packet.stream_index==videoStream) {
            // Decode video frame
            avcodec_decode_video2(pCodecCtx, pFrame, &amp;frameFinished, &amp;packet);
        }
		
	}
	return frameFinished!=0;
}
</pre>

<h6 id="currentimage方法">currentImage方法</h6>

<p>获取当前的UIImage对象，以呈现当前播放的画面</p>
<pre>
-(UIImage *)currentImage {
	if (!pFrame-&gt;data[0]) return nil;
	[self convertFrameToRGB];
	return [self imageFromAVPicture:picture width:outputWidth height:outputHeight];
}

</pre>

<h6 id="convertframetorgb">convertFrameToRGB</h6>

<p>转换音视频帧到RGB</p>
<pre>
-(void)convertFrameToRGB {	
	sws_scale (img_convert_ctx, pFrame-&gt;data, pFrame-&gt;linesize,
			   0, pCodecCtx-&gt;height,
			   picture.data, picture.linesize);	
}

</pre>

<h6 id="uiimage-imagefromavpictureavpicturepict-widthintwidth-heightintheight方法">(UIImage *)imageFromAVPicture:(AVPicture)pict width:(int)width height:(int)height方法</h6>

<p>把AVPicture转换成UIImage把音视频画面显示出来</p>
<pre>
-(UIImage *)imageFromAVPicture:(AVPicture)pict width:(int)width height:(int)height {
	CGBitmapInfo bitmapInfo = kCGBitmapByteOrderDefault;
	CFDataRef data = CFDataCreateWithBytesNoCopy(kCFAllocatorDefault, pict.data[0], pict.linesize[0]*height,kCFAllocatorNull);
	CGDataProviderRef provider = CGDataProviderCreateWithCFData(data);
	CGColorSpaceRef colorSpace = CGColorSpaceCreateDeviceRGB();
	CGImageRef cgImage = CGImageCreate(width, 
									   height, 
									   8, 
									   24, 
									   pict.linesize[0], 
									   colorSpace, 
									   bitmapInfo, 
									   provider, 
									   NULL, 
									   NO, 
									   kCGRenderingIntentDefault);
	CGColorSpaceRelease(colorSpace);
	UIImage *image = [UIImage imageWithCGImage:cgImage];
	CGImageRelease(cgImage);
	CGDataProviderRelease(provider);
	CFRelease(data);
	
	return image;
}
</pre>

<h2 id="reference">Reference</h2>

<p><a href="https://github.com/coderyi/Eleven">ElevenPlayer</a>: 这是我用ffmpeg写的iOS万能播放器。</p>

<p><a href="http://cnbin.github.io/blog/2015/05/19/iospei-zhi-ffmpegkuang-jia/">iOS配置FFmpeg框架</a></p>

<p><a href="https://zh.wikipedia.org/wiki/FFmpeg">FFmpeg-wikipedia</a></p>

<p><a href="https://www.vitamio.org/docs/Basic/2013/0508/14.html">Vitamio测试网络视频地址</a></p>

<p><a href="http://blog.csdn.net/leixiaohua1020/article/details/14214577"> FFMPEG结构体分析-系列文章</a>:包括AVFrame、AVFormatContext、AVCodecContext、AVIOContext、AVCodec、AVStream、AVPacket</p>

<p><a href="http://blog.csdn.net/column/details/ffmpeg-devel.html">FFmpeg开发和使用有关的文章的汇总</a></p>

<p><a href="https://www.ffmpeg.org/">ffmpeg 官网</a></p>

<p><a href="https://github.com/FFmpeg/FFmpeg">FFmpeg GitHub source code</a></p>

<p>作者 ：<a href="https://github.com/coderyi/blog">coderyi</a></p>

<p>转载请加原文链接:<a href="https://github.com/coderyi/blog/blob/master/articles/2015/0826_ffmpeg_iOS_iframeextractor.md">https://github.com/coderyi/blog/blob/master/articles/2015/0826_ffmpeg_iOS_iframeextractor.md</a></p>


  		
	  </article>
    </div>

</div>

<div class="article-meta">
    2015-08-26
     • Category: 
        
        <a href="/categories//#iOS-ref" >Ios</a>
        
    
     • Tag: 
        
            <a href="/tags//#音视频-ref" >音视频</a>
        
    
</div>



	<div class="article-author">
    <div class="avatar">
    <img width="50" height="50" src="/images/logo.png" alt=" Avatar"/>
    </div>
    <div class="name">
        <h4><b>coderyi</b> </h4>
        about iOS ,CS and my code life 
    </div>
</div>


	
	    <div id="disqus_thread"></div>
<script type="text/javascript">
    var disqus_shortname = 'coderyi';
	(function() {
	    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
	    dsq.src = 'https://' + disqus_shortname + '.disqus.com/embed.js';
	    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

	


<div class="cnzz"><script src="http://s4.cnzz.com/z_stat.php?id=1255123325&web_id=1255123325" language="JavaScript"></script> </div>


        </div>
      </div>
    </div>

    </body>
</html>
